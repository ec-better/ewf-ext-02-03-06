{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-ext-02-03-06 - NDVI long term averages of growing season time series per parcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI long term averages of growing season time series per parcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'NDVI long term averages of growing season time series per parcel'),\n",
    "                ('abstract', 'NDVI long term averages of growing season time series per parcel'),\n",
    "                ('id', 'ewf-ext-02-03-06')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((-8.864205 38.88616500000001, -8.864205 38.986165, -8.964205000000002 38.986165, -8.964205000000002 38.88616500000001, -8.864205 38.88616500000001))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'P001'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggIndex = dict([('id', 'aggIndex'),\n",
    "                 ('value', 'better-ext-02-03-02'),\n",
    "                 ('title', 'NDVI growing season statistics catalog index'),\n",
    "                 ('abstract', 'index to access ndvi catalog'),\n",
    "                 ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggApikey = dict([('id', 'aggApikey'),\n",
    "                  ('value', ''),\n",
    "                  ('title', 'NDVI growing season statistics catalog apikey'),\n",
    "                  ('abstract', 'apikey to access ndvi catalog'),\n",
    "                  ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the NDVI stats' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2015, 2015\n",
    "#difNdvi\n",
    "#input_identifiers = ('LE07_ndviStats_P001_2015005_2015365.xlsx', 'LE07_ndviStats_P001_2015005_2015365.xlsx')\n",
    "#'LE07_ndviStats_P001_2015005_2015365.xlsx', 'LE07_ndviStats_P001_2016005_2016365.xlsx', 'LE07_ndviStats_P001_2017005_2017365.xlsx'\n",
    "\n",
    "input_identifiers = ('C510F577367CBA847E7141B4E4186C7A5EEBEC78', 'E58456AA001B0A163CE829A579EFE1F4D10D2580', '72212D9D0CB3D6A925FF97755A5A25386E8B9BF0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ['https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=C510F577367CBA847E7141B4E4186C7A5EEBEC78','https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=E58456AA001B0A163CE829A579EFE1F4D10D2580','https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=72212D9D0CB3D6A925FF97755A5A25386E8B9BF0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/dev/ewf-ext-02-03-02/src/main/app-resources/notebook/libexec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_metadata (input_refs):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        # since the search is by identifier \n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,startdate,enddate,wkt,title',creds='{}:{}'.format(aggIndex['value'],aggApikey['value']))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = datetime.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load metadata from catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Loading metadata from catalog' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "input_metadata = get_input_metadata (input_references)\n",
    "\n",
    "# order by startdate\n",
    "input_metadata = input_metadata.sort_values(by='startdate')\n",
    "\n",
    "input_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute Long Term Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file paths\n",
    "#file_list = [os.path.join(data_path, in_id.split('/')[-1]) for in_id in input_identifiers]\n",
    "file_list = [os.path.join(data_path, os.path.basename(enclosure).split('?')[0]) for enclosure in input_metadata['enclosure']]\n",
    "\n",
    "# load data into a python dictionary\n",
    "# key -> variable name\n",
    "# content -> list of pandas dataframe, one per season (TS)\n",
    "data = {}\n",
    "\n",
    "var_names = ['start_growing_season', 'end_growing_season', 'smooth_ndvi', 'dif_ndvi', 'cumulative_ndvi', 'peak_ndvi']\n",
    "\n",
    "for var in var_names:\n",
    "\n",
    "    df_list = []\n",
    "    for f in file_list:\n",
    "        df = pd.read_excel (f, sheet_name=var)\n",
    "        #print (df)\n",
    "    \n",
    "        # remove useless columns\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            \n",
    "            df = df.drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        if 'start_growing_season_doy_avg' in df.columns:\n",
    "\n",
    "            # drop date\n",
    "            df = df.drop(columns=['start_growing_season_date_avg'])\n",
    "            \n",
    "            \n",
    "        if 'start_growing_season_doy_mode' in df.columns:\n",
    "\n",
    "            # drop date\n",
    "            df = df.drop(columns=['start_growing_season_date_mode'])\n",
    "            \n",
    "            \n",
    "        if 'end_growing_season_doy_avg' in df.columns:\n",
    "\n",
    "            # drop date\n",
    "            df = df.drop(columns=['end_growing_season_date_avg'])\n",
    "            \n",
    "            \n",
    "        if 'end_growing_season_doy_mode' in df.columns:\n",
    "\n",
    "            # drop date\n",
    "            df = df.drop(columns=['end_growing_season_date_mode'])\n",
    "    \n",
    "        df_list.append(df)\n",
    "        \n",
    "    data[var] = df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new python dictionary to store LTAs\n",
    "LTA_data = {}\n",
    "\n",
    "# to each var computes mean\n",
    "#var_names = ['start_growing_season', 'end_growing_season', 'dif_ndvi', 'cumulative_ndvi', 'peak_ndvi']\n",
    "#var_names = ['end_growing_season']\n",
    "for var in var_names:\n",
    "    \n",
    "    entry = [data[var][0]['start_date'], data[var][-1]['end_date']]\n",
    "    \n",
    "    cnames = data[var][0].columns\n",
    "    \n",
    "    for c in cnames:\n",
    "    \n",
    "        if not('start_date' in c) and not('end_date' in c):\n",
    "            \n",
    "            # concatnate all columns of var\n",
    "            df_concat = pd.concat( (d[c] for d in data[var]) )\n",
    "\n",
    "            # group by row index\n",
    "            by_row_index = df_concat.groupby(df_concat.index)\n",
    "            df_means = by_row_index.mean()\n",
    "\n",
    "            # create new dataframe where first column is the startdate of the first set of data\n",
    "            # and enddate is the enddate os the last set of data\n",
    "            # and var is the mean value\n",
    "            entry.append(df_means)\n",
    "    \n",
    "    LTA_data[var] = pd.concat(entry, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add str date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTA_data['start_growing_season']['start_growing_season_doy_avg'] = int(LTA_data['start_growing_season']['start_growing_season_doy_avg'])\n",
    "LTA_data['start_growing_season']['start_growing_season_date_avg'] = LTA_data['start_growing_season'].apply(lambda row: datetime.datetime.strptime(str(row['start_date'].year) + str(int(row['start_growing_season_doy_avg'])), \"%Y%j\").strftime(\"%d/%b\"), axis=1)\n",
    "LTA_data['start_growing_season']['start_growing_season_date_mode'] = LTA_data['start_growing_season'].apply(lambda row: datetime.datetime.strptime(str(row['start_date'].year) + str(int(row['start_growing_season_doy_mode'])), \"%Y%j\").strftime(\"%d/%b\"), axis=1)\n",
    "\n",
    "\n",
    "LTA_data['end_growing_season']['end_growing_season_doy_avg'] = int(LTA_data['end_growing_season']['end_growing_season_doy_avg'])\n",
    "LTA_data['end_growing_season']['end_growing_season_date_avg'] = LTA_data['end_growing_season'].apply(lambda row: datetime.datetime.strptime(str(row['end_date'].year) + str(int(row['end_growing_season_doy_avg'])), \"%Y%j\").strftime(\"%d/%b\"), axis=1)\n",
    "LTA_data['end_growing_season']['end_growing_season_date_mode'] = LTA_data['end_growing_season'].apply(lambda row: datetime.datetime.strptime(str(row['end_date'].year) + str(int(row['end_growing_season_doy_mode'])), \"%Y%j\").strftime(\"%d/%b\"), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_parts = file_list[0].split('/')[-1].split('_')\n",
    "\n",
    "mission = name_parts[0]\n",
    "prod = name_parts[1]\n",
    "aoi_name = name_parts[2]\n",
    "\n",
    "start_date = str(LTA_data['start_growing_season']['start_date'][0].year)\n",
    "end_date = str(LTA_data['start_growing_season']['end_date'][0].year)\n",
    "\n",
    "excel_output_name = '_'.join(['LTA', mission, prod, aoi_name, start_date, end_date]) + '.xlsx'\n",
    "    \n",
    "excel_output_name = os.path.join(output_folder, excel_output_name)\n",
    "\n",
    "print(excel_output_name)\n",
    "\n",
    "with pd.ExcelWriter(excel_output_name) as writer:  # doctest: +SKIP\n",
    "    \n",
    "    for key in var_names:\n",
    "    \n",
    "        LTA_data[key].to_excel(writer, sheet_name=key)\n",
    "\n",
    "write_properties_file(excel_output_name, LTA_data['start_growing_season']['start_date'][0], LTA_data['start_growing_season']['end_date'][0], regionOfInterest['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
